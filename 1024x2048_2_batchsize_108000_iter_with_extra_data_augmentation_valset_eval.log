Loading and preparing results...
DONE (t=0.78s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=10.76s).
Accumulating evaluation results...
DONE (t=0.63s).
INFO json_dataset_evaluator.py: 222: ~~~~ Mean and per-category AP @ IoU=[0.50,0.95] ~~~~
INFO json_dataset_evaluator.py: 223: 47.7
INFO json_dataset_evaluator.py: 234: bicycle: 39.2
INFO json_dataset_evaluator.py: 234: bus: 64.1
INFO json_dataset_evaluator.py: 234: person: 50.2
INFO json_dataset_evaluator.py: 234: train: 36.1
INFO json_dataset_evaluator.py: 234: truck: 42.3
INFO json_dataset_evaluator.py: 234: motorcycle: 37.0
INFO json_dataset_evaluator.py: 234: car: 63.5
INFO json_dataset_evaluator.py: 234: rider: 49.5
INFO json_dataset_evaluator.py: 235: ~~~~ Summary metrics ~~~~
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.477
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.718
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.507
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.248
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.486
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.651
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.305
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.560
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.622
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.372
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.633
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.779
INFO task_evaluation.py:  61: Evaluating bounding boxes is done!
INFO task_evaluation.py: 104: Evaluating segmentations
Loading and preparing results...
DONE (t=1.45s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *segm*
DONE (t=12.61s).
Accumulating evaluation results...
DONE (t=0.64s).
INFO json_dataset_evaluator.py: 222: ~~~~ Mean and per-category AP @ IoU=[0.50,0.95] ~~~~
INFO json_dataset_evaluator.py: 223: 40.5
INFO json_dataset_evaluator.py: 234: bicycle: 24.8
INFO json_dataset_evaluator.py: 234: bus: 60.3
INFO json_dataset_evaluator.py: 234: person: 38.5
INFO json_dataset_evaluator.py: 234: train: 48.3
INFO json_dataset_evaluator.py: 234: truck: 42.0
INFO json_dataset_evaluator.py: 234: motorcycle: 24.8
INFO json_dataset_evaluator.py: 234: car: 53.6
INFO json_dataset_evaluator.py: 234: rider: 31.7
INFO json_dataset_evaluator.py: 235: ~~~~ Summary metrics ~~~~
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.405
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.676
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.410
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.137
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.376
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.621
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.284
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.475
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.513
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.243
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.506
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.706
INFO task_evaluation.py:  65: Evaluating segmentations is done!
INFO task_evaluation.py: 181: copypaste: Dataset: cityscapes_fine_instanceonly_seg_val
INFO task_evaluation.py: 183: copypaste: Task: box
INFO task_evaluation.py: 186: copypaste: AP,AP50,AP75,APs,APm,APl
INFO task_evaluation.py: 187: copypaste: 0.4772,0.7178,0.5071,0.2483,0.4864,0.6515
INFO task_evaluation.py: 183: copypaste: Task: mask
INFO task_evaluation.py: 186: copypaste: AP,AP50,AP75,APs,APm,APl
INFO task_evaluation.py: 187: copypaste: 0.4049,0.6764,0.4103,0.1366,0.3755,0.6209
